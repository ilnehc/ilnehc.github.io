<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Li's Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link rel="stylesheet" href="./assets/academicons-1.9.4/css/academicons.min.css"/>
  <link href='css/style.css' rel='stylesheet' type='text/css'>
  <link href="assets/fontawesome-free-6.7.2/css/fontawesome.css" rel="stylesheet" />
  <link href="assets/fontawesome-free-6.7.2/css/brands.css" rel="stylesheet" />
  <link href="assets/fontawesome-free-6.7.2/css/solid.css" rel="stylesheet" />
  <link href="assets/fontawesome-free-6.7.2/css/sharp-thin.css" rel="stylesheet" />
  <link href="assets/fontawesome-free-6.7.2/css/duotone-thin.css" rel="stylesheet" />
  <link href="assets/fontawesome-free-6.7.2/css/sharp-duotone-thin.css" rel="stylesheet" />
</head>

<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2" style="display:flex;align-items:flex-start">
          <div class="sticky">
            <figure class="image is-128x128">
              <img class="is-rounded" src="./assets/images/Li.png">
            </figure>
            <br>
            <div class="content">
              <h3>Li Chen</h3>
              <h6>(陈立)</h6>
            </div>
            <!-- details -->
            <!-- <div class="details">
              <h3>EMAIL</h3>
              <p><a href="mailto:ilnehc@umich.edu">ilnehc<br>[at]umich[dot]edu</a></p>
            </div> -->
            <!-- social network icons -->
            <div class="social">
              <a href="mailto:ilnehc@umich.edu" target="_blank">
                <span class="fa-solid fa-square-envelope fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://github.com/ilnehc" target="_blank">
                <span class="fa-brands fa-square-github fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=ulZxvY0AAAAJ&hl=en" target="_blank">
                <span class="ai ai-google-scholar-square ai-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://www.linkedin.com/in/li-chen-30b256167/" target="_blank">
                <span class="fa-brands fa-linkedin fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://x.com/ilnehc" target="_blank">
                <span class="fa-brands fa-square-x-twitter fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
            </div>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <p class="menu-label"><b>Quick Links</b></p>
              <ul class="menu-list">
                <!-- <li><a href="#news">News</a></li> -->
                <li><a href="#intro">Intro</a></li>
                <li><a href="#research">Research</a></li>
                <li><a href="#activity">Activity</a></li>
                <li><a href="#awards">Honors</a></li>
              </ul>
            </div>
          </div>



        </div>
        <div class="column">
          <div class="content">
            <!--News-->
            <!-- <h3 id="news">News</h3>
            <ul style="color: rgb(50, 50, 50);">
              <li><span>July, 2023 - Two papers (<a href="https://github.com/OpenDriveLab/DriveAdapter" target="_blank"><u>DriveAdapter</u></a>, <a href="https://github.com/OpenDriveLab/OccNet" target="_blank"><u>OccNet</u></a>) get accepted to ICCV 2023. DriveAdapter is listed as an oral presentation.</span></li>
              <li><span>June, 2023 - <a href="https://github.com/OpenDriveLab/UniAD" target="_blank"><u>UniAD</u></a> won the <b>Best Paper Award</b> of CVPR 2023 !!!</span></li>
              <li><span>June, 2023 - We organized the <a href="https://opendrivelab.com/e2ead/cvpr23.html" target="_blank"><u>End-to-end Autonomous Driving: Emerging Tasks and Challenges</u></a> Workshop on CVPR 2023.</span></li>
              <li><span>May, 2023 - We held the <a href="https://opendrivelab.com/sr4ad/iclr23.html" target="_blank"><u>Scene Representations for Autonomous Driving Workshop</u></a> on ICLR 2023.</span></li>
              <li><span>Mar, 2023 - CVPR 2023 paper <a href="https://github.com/OpenDriveLab/UniAD" target="_blank"><u>UniAD</u></a> is accepted as <b>award candidate</b> (12/9155) !!</span></li>
              <li><span>Mar, 2023 - Three papers (<a href="https://github.com/OpenDriveLab/UniAD" target="_blank"><u>UniAD</u></a>, <a href="https://github.com/OpenDriveLab/ThinkTwice" target="_blank"><u>ThinkTwice</u></a>, <a href="https://github.com/OpenDriveLab/Birds-eye-view-Perception" target="_blank"><u>FocalDistiller</u></a>) get accepted to CVPR 2023.</span></li>
            </ul> -->

            <!--Intro-->
            <h3 id="intro">Intro</h3>
            <p style="color: rgb(50, 50, 50);">
              I am currently pursuing a PhD at the University of Hong Kong (HKU), while also conducting research at <a href="https://opendrivelab.com/" target="_blank"><u>OpenDriveLab</u></a>. 
              I work under the supervision of Prof. <a href="http://luoping.me/" target="_blank"><u>Ping LUO</u></a> and Prof. <a href="https://datascience.hku.hk/people/hongyang-li/" target="_blank"><u>Hongyang LI</u></a>.
              I earned my Master's in Robotics from the Robotics Institute at the University of Michigan, Ann Arbor, in 2020, after a Bachelor's degree in Mechanical Engineering from Shanghai Jiao Tong University in 2019. <br>
              <br>
              My research interests primarily focus on robotics, encompassing areas such as autonomous driving, robot learning, and robotic systems. Representative projects are <span style="background-color:#ffffd0">highlighted</span> below.
            </p>
            <!-- [<a href = "">CV</a>].<br/><br/> -->


            <!--Research-->
            <h3 id="research">Research</h3> 
            <p><small>(*: Equal contribution. †: Project lead.)</small></p>


            <h4>Selected Publications <span>(See all <a href="https://scholar.google.com/citations?user=ulZxvY0AAAAJ&hl=en" target="_blank"><u>here</u></a>.)</span></h4>

            <article class="columns" style="background-color: #ffffd0">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/E2E_survey.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">End-to-end Autonomous Driving: Challenges and Frontiers</b><br>
                    <b style="color:rgb(50, 50, 50);">Li Chen</b>, Penghao Wu, Kashyap Chitta, Bernhard Jaeger, Andreas Geiger, Hongyang Li.<br>
                    <i style="color:rgb(0, 0, 100);">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2024</i><br>
                    <a href="https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving" target="_blank">[<u>page</u>]</a>
                    <a href="https://ieeexplore.ieee.org/document/10614862" target="_blank">[<u>paper</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/CLOVER.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Closed-Loop Visuomotor Control with Generative Expectation for Robotic Manipulation</b><br>
                    Qingwen Bu*, Jia Zeng*, <b style="color:rgb(50, 50, 50);">Li Chen*</b>, Yanchao Yang, Guyue Zhou, Junchi Yan, Ping Luo, Heming Cui, Yi Ma, Hongyang Li.<br>
                    <i style="color:rgb(0, 0, 100);">Advances in Neural Information Processing Systems (NeurIPS), 2024</i><br>
                    <a href="https://arxiv.org/abs/2409.09016" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/CLOVER" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/ViDAR.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Visual Point Cloud Forecasting enables Scalable Autonomous Driving</b><br>
                    Zetong Yang, <b style="color:rgb(50, 50, 50);">Li Chen</b>, Yanan Sun, Hongyang Li.<br>
                    <i style="color:rgb(0, 0, 100);">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</i><br>
                    <b style="color:rgb(255, 100, 0);">Highlight</b> (11.9%)<br>
                    <a href="https://arxiv.org/abs/2312.17655" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/ViDAR" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/GenAD_Vista.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Generalized Predictive Model for Autonomous Driving</b><br>
                    Jiazhi Yang*, Shenyuan Gao*, Yihang Qiu*, <b style="color:rgb(50, 50, 50);">Li Chen<sup>†</sup></b>, Tianyu Li, Bo Dai, Kashyap Chitta, Penghao Wu, Jia Zeng, Ping Luo, Jun Zhang, Andreas Geiger, Yu Qiao, Hongyang Li<sup>†</sup>.<br>
                    <i style="color:rgb(0, 0, 100);">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024</i><br>
                    <b style="color:rgb(255, 100, 0);">Highlight</b> (11.9%)<br>
                    <a href="https://arxiv.org/abs/2403.09630" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/DriveAGI" target="_blank">[<u>dataset</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns" style="background-color: #ffffd0">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/UniAD.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Plannning-oriented Autonomous Driving</b><br>
                    Yihan Hu*, Jiazhi Yang*, <b style="color:rgb(50, 50, 50);">Li Chen*<sup>†</sup></b>, Keyu Li*, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, Lewei Lu, Xiaosong Jia, Qiang Liu, Jifeng Dai, Yu Qiao, Hongyang Li<sup>†</sup>.<br>
                    <i style="color:rgb(0, 0, 100);">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</i><br>
                    <b style="color:rgb(255, 100, 0);">Best Paper</b> (2/9155)<br>
                    <a href="https://arxiv.org/abs/2212.10156" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/UniAD" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/PPGeo.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling</b><br>
                    Penghao Wu, <b style="color:rgb(50, 50, 50);">Li Chen</b>, Hongyang Li, Xiaosong Jia, Junchi Yan, Yu Qiao.<br>
                    <i style="color:rgb(0, 0, 100);">International Conference on Learning Representations (ICLR), 2023</i><br>
                    <a href="https://arxiv.org/abs/2212.10156" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/PPGeo" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/TCP.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline</b><br>
                    Penghao Wu*, Xiaosong Jia*, <b style="color:rgb(50, 50, 50);">Li Chen*</b>, Junchi Yan, Hongyang Li, Yu Qiao.<br>
                    <i style="color:rgb(0, 0, 100);">Advances in Neural Information Processing Systems (NeurIPS), 2022</i><br>
                    <a href="https://arxiv.org/abs/2206.08129" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenPerceptionX/TCP" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/ST-P3.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning</b><br>
                    Shengchao Hu, <b style="color:rgb(50, 50, 50);">Li Chen<sup>†</sup></b>, Penghao Wu, Hongyang Li, Junchi Yan, Dacheng Tao.<br>
                    <i style="color:rgb(0, 0, 100);">European Conference on Computer Vision (ECCV), 2022</i><br>
                    <a href="https://arxiv.org/abs/2207.07601" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenPerceptionX/ST-P3" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns" style="background-color: #ffffd0">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/PersFormer.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark</b><br>
                    <b style="color:rgb(50, 50, 50);">Li Chen*<sup>†</sup></b>, Chonghao Sima*, Yang Li*, Zehan Zheng, Jiajie Xu, Xiangwei Geng, Hongyang Li<sup>†</sup>, Conghui He, Jianping Shi, Yu Qiao, Junchi Yan.<br>
                    <i style="color:rgb(0, 0, 100);">European Conference on Computer Vision (ECCV), 2022</i><br>
                    <b style="color:rgb(255, 100, 0);">Oral Presentation</b> (2.7%)<br>
                    <a href="https://arxiv.org/abs/2203.11089" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/PersFormer_3DLane" target="_blank">[<u>code</u>]</a>
                    <a href="https://github.com/OpenDriveLab/OpenLane" target="_blank">[<u>dataset</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <h4>Preprint</h4>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/TopoNet.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Graph-based Topology Reasoning for Driving Scenes</b><br>
                    Tianyu Li*, <b style="color:rgb(50, 50, 50);">Li Chen*<sup>†</sup></b>, Huijie Wang, Yang Li, Jiazhi Yang, Xiangwei Geng, Shengyin Jiang, Yuting Wang, Hang Xu, Chunjing Xu, Junchi Yan, Ping Luo, Hongyang Li.<br>
                    arXiv preprint, 2023<br>
                    <a href="https://arxiv.org/abs/2304.05277" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenDriveLab/TopoNet" target="_blank">[<u>code</u>]</a>
                    <a href="https://github.com/OpenDriveLab/OpenLane-V2" target="_blank">[<u>dataset</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="assets/images/openpilot.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b style="color:rgb(0, 0, 0);">Level 2 Autonomous Driving on a Single Device: Diving into the Devils of Openpilot</b><br>
                    <b style="color:rgb(50, 50, 50);">Li Chen*<sup>†</sup></b>, Tutian Tang*, Zhitian Cai*, Yang Li*, Penghao Wu, Hongyang Li, Jianping Shi, Junchi Yan, Yu Qiao.<br>
                    Tech report, 2022<br>
                    <a href="https://sites.google.com/view/openpilot-deepdive/home" target="_blank">[<u>page</u>]</a>
                    <a href="https://arxiv.org/abs/2206.08176" target="_blank">[<u>paper</u>]</a>
                    <a href="https://github.com/OpenPerceptionX/Openpilot-Deepdive" target="_blank">[<u>code</u>]</a>
                  </p>
                </div>
              </div>
            </article>

            <h3 id="activity">Activity</h3> 

            <ul style="color: rgb(50, 50, 50);">
              <li>Workshop/Tutorial Organizer: 
                <ul>
                  <li><a href="https://coop-intelligence.github.io/" target="_blank"><u>2nd Workshop on Multi-Agent Embodied Intelligent Systems</u></a>, CVPR 2025</li>
                  <li><a href="https://coop-intelligence.github.io/eccv2024/" target="_blank"><u>1st Workshop on Cooperative Intelligence for Embodied AI</u></a>, ECCV 2024</li>
                  <li><a href="https://opendrivelab.com/cvpr2024/tutorial/" target="_blank"><u>Towards Building AGI in Autonomy and Robotics</u></a>, CVPR 2024 (Primary Organizer)</li>
                  <li><a href="https://opendrivelab.com/e2ead/cvpr23.html" target="_blank"><u>End-to-end Autonomous Driving: Emerging Tasks and Challenges</u></a>, CVPR 2023</li>
                  <li><a href="https://opendrivelab.com/sr4ad/iclr23.html" target="_blank"><u>Workshop on Scene Representations for Autonomous Driving</u></a>, ICLR 2023</li>
                </ul>
              </li>
              <li>Reviewer: 
                <ul>
                  <li>Journal: Nature Communications, IEEE T-RO, IEEE RA-L</li>
                  <li>Conference: CVPR, ICCV, ECCV, NeurIPS, ICLR, ICML, RSS, ICRA, IROS, WACV</li>
                </ul>
              </li>
              <li>Teaching Assitant: 
                <ul>
                  <li>DASC7606 Deep Learning (2022-2023 Spring, 2023-2024 Spring)</li>
                  <li>COMP7506 Smart Phone Apps Development (2024-2025 Spring)</li>
                </ul>
            </ul>

            <h3 id="awards">Honors</h3> 

            <ul style="color: rgb(50, 50, 50);">
              <li>Outstanding/Top Reviewer: CVPR'23, NeurIPS'23</li>
              <li>The World Artificial Intelligence Conference (WAIC) Yunfun Award, 2023</li>
              <li>HKU Presidential PhD Scholar (HKU-PS), 2023</li>
              <li>Outstanding Graduate of Shanghai, 2019</li>
            </ul>


          </div>
        </div>
      </div>
    </div>
  </section>

  <script>
    var elm = document.querySelector('#sidebar');
    var ms = new MenuSpy(elm, {
      activeClass: 'is-active'
    });
  </script>
</body>

</html>